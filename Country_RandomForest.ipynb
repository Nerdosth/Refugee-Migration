{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading and transforming data: \n",
    "import pandas as pd\n",
    "refugee_df = pd.read_csv('Resources/demographic_ml_df.csv')\n",
    "\n",
    "#preprocessing data: \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#building models:\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "#evaluate models: \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "\n",
    "#displaying models:\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 61199 rows and 26 columns.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rows_and_cols = refugee_df.shape\n",
    "print('There are {} rows and {} columns.\\n'.format(\n",
    "    rows_and_cols[0], rows_and_cols[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows that for countries that do not report demographic data. \n",
    "\n",
    "r_df = refugee_df.loc[(refugee_df['Male total'] != 0) | (refugee_df['Female total'] != 0)].reset_index()\n",
    "r_df.drop(['index','Male total','Unnamed: 0', 'Female total'], axis=1, inplace=True)\n",
    "r_df.reset_index(drop=True, inplace=True)\n",
    "r_df = r_df.rename(columns={'total': 'total_refugees'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "X = r_df.drop('country_asylum', axis=1)\n",
    "y = r_df['country_asylum']\n",
    "\n",
    "# One hot encode the categorical features\n",
    "cat_features = ['country_origin']\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(X[cat_features])\n",
    "X_encoded = encoder.transform(X[cat_features])\n",
    "\n",
    "# Concatenate the encoded features with the numerical features\n",
    "num_features = ['share_borders', 'total_refugees','recognized_decisions', 'complementary_protection', 'rejected','otherwise_closed', 'total_decisions', 'female_0to4','female_5to11','female_12to17','female_18to59','female_60','female_other','male_0to4','male_5to11','male_12to17','male_18to59','male_60','male_other','unknown_demographic']\n",
    "X_num = X[num_features].values\n",
    "X_encoded = pd.DataFrame(X_encoded.toarray(), columns=encoder.get_feature_names_out(cat_features))\n",
    "X_processed = pd.concat([pd.DataFrame(X_num, columns=num_features), X_encoded], axis=1)\n",
    "X_processed.fillna(0, inplace=True)\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\erdos\\anaconda3\\envs\\PythonDataOne\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best accuracy score: 0.555686274509804\n"
     ]
    }
   ],
   "source": [
    "#Determine which parameters are best for the Random Forest Classifier using Grid Search CV. \n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 4, 6]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=rf_clf, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and the best accuracy score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Best accuracy score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sierra Leone' 'Sudan' 'Brazil' ... 'Malaysia' 'Switzerland' 'Turkey']\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier with 100 trees\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, max_depth = 30, min_samples_split = 2)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.583552556330779\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the accuracy of the model\n",
    "accuracy = rf_clf.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12804\\2763984837.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Apply the preprocessor to the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mX_processed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Split the data into training and testing sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Define the columns to encode\n",
    "cat_features = ['country_origin']\n",
    "\n",
    "# Create a ColumnTransformer object to apply the encoders\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('label', LabelEncoder(), ['country_asylum']),\n",
    "        ('onehot', OneHotEncoder(), cat_features)\n",
    "    ])\n",
    "\n",
    "# Apply the preprocessor to the data\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 4, 6]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=rf_clf, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and the best accuracy score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Best accuracy score:\", best_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
