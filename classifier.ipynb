{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "refugee_df = pd.read_csv('Resources/demographic_ml_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "r_df = refugee_df.loc[(refugee_df['Male total'] != 0) | (refugee_df['Female total'] != 0)]\n",
    "r_df = r_df.drop(['Male total', 'Unnamed: 0', 'Female total'], axis=1).reset_index(drop=True)\n",
    "r_df.rename(columns={'total': 'total_refugees'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target variable\n",
    "X = r_df.drop(['country_asylum'], axis=1)\n",
    "y = r_df['country_asylum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to encode\n",
    "cat_features = ['country_origin']\n",
    "\n",
    "# Create a ColumnTransformer object to apply the encoder\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(), cat_features)\n",
    "    ])\n",
    "\n",
    "# Apply the preprocessor to the data\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Create a LabelEncoder for country_asylum\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the country_asylum column in y\n",
    "y_processed = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00        35\n",
      "           2       0.00      0.00      0.00        57\n",
      "           3       0.00      0.00      0.00        22\n",
      "           5       0.00      0.00      0.00       195\n",
      "           6       0.06      0.09      0.07        47\n",
      "           7       0.00      0.00      0.00        37\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       0.00      0.00      0.00        18\n",
      "          11       0.03      0.15      0.05        55\n",
      "          12       0.00      0.00      0.00       251\n",
      "          13       0.00      0.00      0.00         9\n",
      "          14       0.00      0.00      0.00        92\n",
      "          15       0.00      0.00      0.00        21\n",
      "          16       0.00      0.00      0.00        34\n",
      "          17       0.04      0.04      0.04        46\n",
      "          18       0.00      0.00      0.00       164\n",
      "          19       0.02      0.03      0.03        58\n",
      "          20       0.00      0.00      0.00        21\n",
      "          21       0.00      0.00      0.00        27\n",
      "          22       0.00      0.00      0.00        76\n",
      "          23       0.00      0.00      0.00       179\n",
      "          24       0.00      0.00      0.00         1\n",
      "          25       0.02      0.09      0.03        76\n",
      "          26       0.00      0.02      0.01        59\n",
      "          27       0.00      0.00      0.00        30\n",
      "          28       0.00      0.00      0.00        53\n",
      "          29       0.04      0.17      0.06        63\n",
      "          30       0.00      0.00      0.00         1\n",
      "          31       0.08      0.12      0.10       105\n",
      "          33       0.00      0.00      0.00        61\n",
      "          34       0.00      0.00      0.00        63\n",
      "          35       0.03      0.04      0.04       124\n",
      "          36       0.00      0.00      0.00        66\n",
      "          37       0.37      0.19      0.25        54\n",
      "          38       0.00      0.00      0.00         2\n",
      "          39       0.00      0.00      0.00        32\n",
      "          40       0.00      0.00      0.00        27\n",
      "          41       0.01      0.05      0.02        59\n",
      "          42       0.00      0.00      0.00        36\n",
      "          43       0.00      0.00      0.00         7\n",
      "          44       0.00      0.00      0.00       131\n",
      "          45       0.02      0.07      0.03       131\n",
      "          46       0.12      0.22      0.16        27\n",
      "          47       0.02      0.05      0.03        19\n",
      "          48       0.00      0.00      0.00        15\n",
      "          49       0.00      0.00      0.00        73\n",
      "          50       0.01      0.04      0.02        76\n",
      "          51       0.00      0.00      0.00         5\n",
      "          52       0.07      0.05      0.06       400\n",
      "          53       0.01      0.02      0.02        81\n",
      "          54       0.07      0.11      0.08        37\n",
      "          55       0.00      0.00      0.00        48\n",
      "          56       0.07      0.02      0.03       317\n",
      "          57       0.00      0.00      0.00        85\n",
      "          58       0.00      0.00      0.00        17\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00        28\n",
      "          61       0.03      0.05      0.03        77\n",
      "          62       0.00      0.00      0.00        35\n",
      "          63       0.00      0.00      0.00         4\n",
      "          65       0.00      0.00      0.00        16\n",
      "          66       0.00      0.00      0.00        21\n",
      "          67       0.00      0.00      0.00         8\n",
      "          68       0.00      0.00      0.00       101\n",
      "          69       0.00      0.00      0.00        72\n",
      "          70       0.00      0.00      0.00        19\n",
      "          71       0.01      0.07      0.02        30\n",
      "          72       0.00      0.00      0.00       131\n",
      "          73       0.00      0.00      0.00         3\n",
      "          74       0.00      0.00      0.00         2\n",
      "          75       0.00      0.00      0.00        45\n",
      "          76       0.01      0.01      0.01        73\n",
      "          77       0.00      0.00      0.00        31\n",
      "          78       0.04      0.06      0.05        89\n",
      "          79       0.00      0.00      0.00        32\n",
      "          80       0.00      0.00      0.00        32\n",
      "          81       0.00      0.00      0.00        21\n",
      "          82       0.03      0.04      0.03        84\n",
      "          83       0.00      0.00      0.00        12\n",
      "          84       0.00      0.00      0.00        44\n",
      "          85       0.00      0.00      0.00        71\n",
      "          87       0.00      0.00      0.00        21\n",
      "          88       0.00      0.00      0.00        39\n",
      "          89       0.00      0.00      0.00        10\n",
      "          90       0.00      0.00      0.00        26\n",
      "          91       0.09      0.08      0.09       151\n",
      "          92       0.00      0.00      0.00        65\n",
      "          93       0.00      0.00      0.00        89\n",
      "          94       0.00      0.00      0.00         3\n",
      "          95       0.02      0.01      0.01       123\n",
      "          97       0.00      0.00      0.00         4\n",
      "          98       0.00      0.00      0.00        23\n",
      "          99       0.00      0.00      0.00       104\n",
      "         100       0.00      0.00      0.00        47\n",
      "         101       0.00      0.00      0.00        38\n",
      "         102       0.00      0.00      0.00         4\n",
      "         103       0.33      0.26      0.29        39\n",
      "         104       0.06      0.29      0.10        21\n",
      "         105       0.00      0.00      0.00        71\n",
      "         106       0.04      0.10      0.05       113\n",
      "         107       0.00      0.00      0.00        12\n",
      "         108       0.00      0.00      0.00        13\n",
      "         109       0.00      0.00      0.00        39\n",
      "         111       0.03      0.05      0.04        75\n",
      "         112       0.00      0.00      0.00        15\n",
      "         113       0.00      0.00      0.00        21\n",
      "         114       0.00      0.00      0.00        54\n",
      "         115       0.01      0.02      0.01        95\n",
      "         116       0.00      0.00      0.00         2\n",
      "         117       0.00      0.00      0.00        21\n",
      "         118       0.00      0.00      0.00       107\n",
      "         119       0.05      0.19      0.08        67\n",
      "         120       0.00      0.00      0.00       111\n",
      "         121       0.00      0.00      0.00         1\n",
      "         122       0.00      0.00      0.00        48\n",
      "         124       0.00      0.00      0.00         1\n",
      "         125       0.00      0.00      0.00        42\n",
      "         126       0.02      0.12      0.03        89\n",
      "         127       0.00      0.00      0.00        28\n",
      "         128       0.00      0.00      0.00        10\n",
      "         129       0.00      0.00      0.00         3\n",
      "         130       0.00      0.00      0.00         4\n",
      "         131       0.00      0.00      0.00        14\n",
      "         132       0.00      0.00      0.00        43\n",
      "         133       0.00      0.00      0.00        37\n",
      "         134       0.00      0.00      0.00        58\n",
      "         135       0.00      0.00      0.00        12\n",
      "         136       0.00      0.00      0.00        27\n",
      "         137       0.00      0.00      0.00        61\n",
      "         138       0.00      0.00      0.00         1\n",
      "         139       0.07      0.22      0.11       441\n",
      "         140       0.01      0.02      0.01       115\n",
      "         141       0.00      0.00      0.00        15\n",
      "         142       0.06      0.08      0.06       104\n",
      "         143       0.00      0.00      0.00        79\n",
      "         144       0.00      0.00      0.00        18\n",
      "         145       0.00      0.01      0.01        76\n",
      "         146       0.00      0.00      0.00       126\n",
      "         147       0.00      0.00      0.00        26\n",
      "         148       0.00      0.00      0.00         2\n",
      "         149       0.11      0.07      0.08        90\n",
      "         150       0.00      0.00      0.00       170\n",
      "         151       0.00      0.00      0.00        66\n",
      "         152       0.00      0.00      0.00        29\n",
      "         153       0.01      0.08      0.01        52\n",
      "         154       0.00      0.00      0.00        16\n",
      "         155       0.00      0.00      0.00         1\n",
      "         156       0.06      0.10      0.08        72\n",
      "         157       0.00      0.00      0.00         3\n",
      "         158       0.00      0.00      0.00        62\n",
      "         159       0.00      0.02      0.01        62\n",
      "         160       0.00      0.00      0.00        86\n",
      "\n",
      "    accuracy                           0.04      8743\n",
      "   macro avg       0.01      0.02      0.02      8743\n",
      "weighted avg       0.02      0.04      0.03      8743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 9 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\erdos\\anaconda3\\envs\\PythonDataOne\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\erdos\\anaconda3\\envs\\PythonDataOne\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\erdos\\anaconda3\\envs\\PythonDataOne\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y_processed, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained Decision Tree Classifier\n",
    "joblib.dump(dt_classifier, 'decision_tree_classifier_model.pkl')\n",
    "\n",
    "# Load the classifier model\n",
    "loaded_classifier = joblib.load('decision_tree_classifier_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted asylum country for refugees from Iraq: Egypt\n"
     ]
    }
   ],
   "source": [
    "# Example: Predict the asylum country for refugees from 'USA'\n",
    "country_origin = 'Iraq'\n",
    "\n",
    "# Preprocess the input and make a prediction\n",
    "input_data = preprocessor.transform(pd.DataFrame({'country_origin': [country_origin]}))\n",
    "predicted_asylum = loaded_classifier.predict(input_data)\n",
    "\n",
    "# Convert the predicted label back to its original string representation\n",
    "predicted_asylum_country = le.inverse_transform(predicted_asylum)\n",
    "\n",
    "print(f\"Predicted asylum country for refugees from {country_origin}: {predicted_asylum_country[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonDataOne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
