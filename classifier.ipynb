{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "refugee_df = pd.read_csv('Resources/demographic_ml_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "r_df = refugee_df.loc[(refugee_df['Male total'] != 0) | (refugee_df['Female total'] != 0)]\n",
    "r_df = r_df.drop(['Male total', 'Unnamed: 0', 'Female total'], axis=1).reset_index(drop=True)\n",
    "r_df.rename(columns={'total': 'total_refugees'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target variable\n",
    "X = r_df.drop(['country_asylum'], axis=1)\n",
    "y = r_df['country_asylum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to encode\n",
    "cat_features = ['country_origin']\n",
    "\n",
    "# Create a ColumnTransformer object to apply the encoder\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(), cat_features)\n",
    "    ])\n",
    "\n",
    "# Apply the preprocessor to the data\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Create a LabelEncoder for country_asylum\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the country_asylum column in y\n",
    "y_processed = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        14\n",
      "           1       1.00      0.00      0.00        35\n",
      "           2       1.00      0.00      0.00        57\n",
      "           3       1.00      0.00      0.00        22\n",
      "           5       1.00      0.00      0.00       195\n",
      "           6       0.06      0.09      0.07        47\n",
      "           7       1.00      0.00      0.00        37\n",
      "           8       1.00      0.00      0.00         4\n",
      "           9       1.00      0.00      0.00         5\n",
      "          10       1.00      0.00      0.00        18\n",
      "          11       0.03      0.15      0.05        55\n",
      "          12       1.00      0.00      0.00       251\n",
      "          13       1.00      0.00      0.00         9\n",
      "          14       1.00      0.00      0.00        92\n",
      "          15       1.00      0.00      0.00        21\n",
      "          16       1.00      0.00      0.00        34\n",
      "          17       0.04      0.04      0.04        46\n",
      "          18       1.00      0.00      0.00       164\n",
      "          19       0.02      0.03      0.03        58\n",
      "          20       1.00      0.00      0.00        21\n",
      "          21       1.00      0.00      0.00        27\n",
      "          22       1.00      0.00      0.00        76\n",
      "          23       1.00      0.00      0.00       179\n",
      "          24       1.00      0.00      0.00         1\n",
      "          25       0.02      0.09      0.03        76\n",
      "          26       0.00      0.02      0.01        59\n",
      "          27       1.00      0.00      0.00        30\n",
      "          28       1.00      0.00      0.00        53\n",
      "          29       0.04      0.17      0.06        63\n",
      "          30       1.00      0.00      0.00         1\n",
      "          31       0.08      0.12      0.10       105\n",
      "          33       1.00      0.00      0.00        61\n",
      "          34       1.00      0.00      0.00        63\n",
      "          35       0.03      0.04      0.04       124\n",
      "          36       1.00      0.00      0.00        66\n",
      "          37       0.37      0.19      0.25        54\n",
      "          38       1.00      0.00      0.00         2\n",
      "          39       1.00      0.00      0.00        32\n",
      "          40       1.00      0.00      0.00        27\n",
      "          41       0.01      0.05      0.02        59\n",
      "          42       1.00      0.00      0.00        36\n",
      "          43       1.00      0.00      0.00         7\n",
      "          44       1.00      0.00      0.00       131\n",
      "          45       0.02      0.07      0.03       131\n",
      "          46       0.12      0.22      0.16        27\n",
      "          47       0.02      0.05      0.03        19\n",
      "          48       1.00      0.00      0.00        15\n",
      "          49       1.00      0.00      0.00        73\n",
      "          50       0.01      0.04      0.02        76\n",
      "          51       1.00      0.00      0.00         5\n",
      "          52       0.07      0.05      0.06       400\n",
      "          53       0.01      0.02      0.02        81\n",
      "          54       0.07      0.11      0.08        37\n",
      "          55       1.00      0.00      0.00        48\n",
      "          56       0.07      0.02      0.03       317\n",
      "          57       1.00      0.00      0.00        85\n",
      "          58       1.00      0.00      0.00        17\n",
      "          59       1.00      0.00      0.00         1\n",
      "          60       1.00      0.00      0.00        28\n",
      "          61       0.03      0.05      0.03        77\n",
      "          62       1.00      0.00      0.00        35\n",
      "          63       1.00      0.00      0.00         4\n",
      "          65       1.00      0.00      0.00        16\n",
      "          66       1.00      0.00      0.00        21\n",
      "          67       1.00      0.00      0.00         8\n",
      "          68       1.00      0.00      0.00       101\n",
      "          69       1.00      0.00      0.00        72\n",
      "          70       1.00      0.00      0.00        19\n",
      "          71       0.01      0.07      0.02        30\n",
      "          72       1.00      0.00      0.00       131\n",
      "          73       1.00      0.00      0.00         3\n",
      "          74       1.00      0.00      0.00         2\n",
      "          75       1.00      0.00      0.00        45\n",
      "          76       0.01      0.01      0.01        73\n",
      "          77       1.00      0.00      0.00        31\n",
      "          78       0.04      0.06      0.05        89\n",
      "          79       1.00      0.00      0.00        32\n",
      "          80       1.00      0.00      0.00        32\n",
      "          81       1.00      0.00      0.00        21\n",
      "          82       0.03      0.04      0.03        84\n",
      "          83       1.00      0.00      0.00        12\n",
      "          84       1.00      0.00      0.00        44\n",
      "          85       1.00      0.00      0.00        71\n",
      "          87       1.00      0.00      0.00        21\n",
      "          88       1.00      0.00      0.00        39\n",
      "          89       1.00      0.00      0.00        10\n",
      "          90       1.00      0.00      0.00        26\n",
      "          91       0.09      0.08      0.09       151\n",
      "          92       1.00      0.00      0.00        65\n",
      "          93       1.00      0.00      0.00        89\n",
      "          94       1.00      0.00      0.00         3\n",
      "          95       0.02      0.01      0.01       123\n",
      "          97       1.00      0.00      0.00         4\n",
      "          98       1.00      0.00      0.00        23\n",
      "          99       1.00      0.00      0.00       104\n",
      "         100       1.00      0.00      0.00        47\n",
      "         101       1.00      0.00      0.00        38\n",
      "         102       1.00      0.00      0.00         4\n",
      "         103       0.33      0.26      0.29        39\n",
      "         104       0.06      0.29      0.10        21\n",
      "         105       1.00      0.00      0.00        71\n",
      "         106       0.04      0.10      0.05       113\n",
      "         107       1.00      0.00      0.00        12\n",
      "         108       1.00      0.00      0.00        13\n",
      "         109       1.00      0.00      0.00        39\n",
      "         111       0.03      0.05      0.04        75\n",
      "         112       1.00      0.00      0.00        15\n",
      "         113       1.00      0.00      0.00        21\n",
      "         114       1.00      0.00      0.00        54\n",
      "         115       0.01      0.02      0.01        95\n",
      "         116       1.00      0.00      0.00         2\n",
      "         117       1.00      0.00      0.00        21\n",
      "         118       1.00      0.00      0.00       107\n",
      "         119       0.05      0.19      0.08        67\n",
      "         120       1.00      0.00      0.00       111\n",
      "         121       1.00      0.00      0.00         1\n",
      "         122       1.00      0.00      0.00        48\n",
      "         124       1.00      0.00      0.00         1\n",
      "         125       1.00      0.00      0.00        42\n",
      "         126       0.02      0.12      0.03        89\n",
      "         127       1.00      0.00      0.00        28\n",
      "         128       1.00      0.00      0.00        10\n",
      "         129       1.00      0.00      0.00         3\n",
      "         130       1.00      0.00      0.00         4\n",
      "         131       1.00      0.00      0.00        14\n",
      "         132       1.00      0.00      0.00        43\n",
      "         133       1.00      0.00      0.00        37\n",
      "         134       1.00      0.00      0.00        58\n",
      "         135       1.00      0.00      0.00        12\n",
      "         136       1.00      0.00      0.00        27\n",
      "         137       1.00      0.00      0.00        61\n",
      "         138       1.00      0.00      0.00         1\n",
      "         139       0.07      0.22      0.11       441\n",
      "         140       0.01      0.02      0.01       115\n",
      "         141       1.00      0.00      0.00        15\n",
      "         142       0.06      0.08      0.06       104\n",
      "         143       1.00      0.00      0.00        79\n",
      "         144       1.00      0.00      0.00        18\n",
      "         145       0.00      0.01      0.01        76\n",
      "         146       1.00      0.00      0.00       126\n",
      "         147       1.00      0.00      0.00        26\n",
      "         148       1.00      0.00      0.00         2\n",
      "         149       0.11      0.07      0.08        90\n",
      "         150       1.00      0.00      0.00       170\n",
      "         151       1.00      0.00      0.00        66\n",
      "         152       1.00      0.00      0.00        29\n",
      "         153       0.01      0.08      0.01        52\n",
      "         154       1.00      0.00      0.00        16\n",
      "         155       1.00      0.00      0.00         1\n",
      "         156       0.06      0.10      0.08        72\n",
      "         157       1.00      0.00      0.00         3\n",
      "         158       1.00      0.00      0.00        62\n",
      "         159       0.00      0.02      0.01        62\n",
      "         160       1.00      0.00      0.00        86\n",
      "\n",
      "    accuracy                           0.04      8743\n",
      "   macro avg       0.75      0.02      0.02      8743\n",
      "weighted avg       0.57      0.04      0.03      8743\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 9 0]]\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y_processed, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred,zero_division=1))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained Decision Tree Classifier\n",
    "joblib.dump(dt_classifier, 'decision_tree_classifier_model.pkl')\n",
    "\n",
    "# Load the classifier model\n",
    "loaded_classifier = joblib.load('decision_tree_classifier_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted asylum country for refugees from Iraq: Egypt\n"
     ]
    }
   ],
   "source": [
    "# Example: Predict the asylum country for refugees from 'USA'\n",
    "country_origin = 'Iraq'\n",
    "\n",
    "# Preprocess the input and make a prediction\n",
    "input_data = preprocessor.transform(pd.DataFrame({'country_origin': [country_origin]}))\n",
    "predicted_asylum = loaded_classifier.predict(input_data)\n",
    "\n",
    "# Convert the predicted label back to its original string representation\n",
    "predicted_asylum_country = le.inverse_transform(predicted_asylum)\n",
    "\n",
    "print(f\"Predicted asylum country for refugees from {country_origin}: {predicted_asylum_country[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonDataOne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
